{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task C: Train RNN on FSDD; quantized; weights in pow2\n",
    "# - same as Task B, custom quant fcn for params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "\n",
    "from utils import get_rec_paths, load_data, train_model, validate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2430, 20, 20]) torch.Size([270, 20, 20]) torch.Size([300, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "# Load from YAML file\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    args = yaml.safe_load(f)\n",
    "\n",
    "# labels and paths in pd frame\n",
    "data = get_rec_paths('./free-spoken-digit-dataset/recordings')\n",
    "\n",
    "# load train, val, test data\n",
    "trainset, validset, trainlabels, validlabels, testset, testlabels = load_data(data,True,**args)\n",
    "print(trainset.shape, validset.shape, testset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSDNN_RNN(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_size, num_layers, output_size):\n",
    "        super(FSDNN_RNN, self).__init__()\n",
    "        self.rnn = torch.nn.RNN(input_size=input_channels, \n",
    "                          hidden_size=hidden_size, \n",
    "                          num_layers=num_layers, \n",
    "                          batch_first=True)  # (batch, seq, features)\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)  # RNN output\n",
    "        out = self.fc(out[:, -1, :])  # Take last time step for classification\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSDNN_RNN_POW2WEIGHTS_Q(torch.nn.Module):\n",
    "    def __init__(self, input_channels, hidden_size, num_layers, output_size):\n",
    "        super(FSDNN_RNN_POW2WEIGHTS_Q, self).__init__()\n",
    "        self.rnn = torch.nn.RNN(input_size=input_channels, \n",
    "                          hidden_size=hidden_size, \n",
    "                          num_layers=num_layers, \n",
    "                          batch_first=True)  # (batch, seq, features)\n",
    "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.bits = 8\n",
    "        self.enable_q = False\n",
    "\n",
    "    # Quantization function\n",
    "    def quantize(self, x, num_bits=8):\n",
    "        scale = x.max() / (2 ** (num_bits-1) - 1)  # Scale factor for quantization\n",
    "        x_quantized = torch.round(x / scale)  # Quantize by scaling and rounding\n",
    "        x_quantized = torch.clamp(x_quantized, -2 ** (num_bits-1), 2 ** (num_bits-1) - 1)  # Clip to valid range\n",
    "        return x_quantized, scale\n",
    "\n",
    "    # Dequantization function\n",
    "    def dequantize(self, x_quantized, scale):\n",
    "        return x_quantized * scale\n",
    "    \n",
    "    def q_sym_noscale(self, x, num_bits=8, num_frac=6):\n",
    "        s = 2 ** (num_bits - 1)\n",
    "        q = torch.round(x * s)\n",
    "        q = torch.clamp(q, -s, s - 1)\n",
    "        q = q / (2 ** num_frac)\n",
    "        return q\n",
    "    \n",
    "    def q_pow2_w(self, win):\n",
    "        sgn = torch.sign(win)\n",
    "        w_q = torch.pow(2, torch.round(torch.log2(torch.abs(win))))\n",
    "        #import pdb; pdb.set_trace()\n",
    "        return sgn * w_q  \n",
    "\n",
    "    # quantized (modified pytorch doc implementation -> fixed layered input)\n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.rnn.batch_first:\n",
    "            x = x.transpose(0, 1)\n",
    "        seq_len, batch_size, _ = x.size()\n",
    "\n",
    "        h_t_minus_1 = torch.zeros(self.rnn.num_layers, batch_size, self.rnn.hidden_size)\n",
    "        h_t = torch.zeros_like(h_t_minus_1)\n",
    "\n",
    "        output = []\n",
    "\n",
    "        if self.enable_q:\n",
    "            x_quantized, scale = self.quantize(x.clone(), self.bits)\n",
    "            x = self.dequantize(x_quantized, scale)\n",
    "            #import pdb; pdb.set_trace()\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            h_t_new = []\n",
    "            for layer in range(self.rnn.num_layers):\n",
    "                if self.enable_q:\n",
    "                    weight_ih = self.q_pow2_w(getattr(self.rnn, f'weight_ih_l{layer}'))\n",
    "                    bias_ih = self.q_pow2_w(getattr(self.rnn, f'bias_ih_l{layer}'))\n",
    "                    weight_hh = self.q_pow2_w(getattr(self.rnn, f'weight_hh_l{layer}'))\n",
    "                    bias_hh = self.q_pow2_w(getattr(self.rnn, f'bias_hh_l{layer}'))\n",
    "                else:\n",
    "                    weight_ih = getattr(self.rnn, f'weight_ih_l{layer}')\n",
    "                    bias_ih = getattr(self.rnn, f'bias_ih_l{layer}')\n",
    "                    weight_hh = getattr(self.rnn, f'weight_hh_l{layer}')\n",
    "                    bias_hh = getattr(self.rnn, f'bias_hh_l{layer}')\n",
    "\n",
    "                xin = x[t] if layer == 0 else h_t_new[layer-1]\n",
    "\n",
    "                h_layer = torch.tanh(\n",
    "                    xin @ weight_ih.T\n",
    "                    + bias_ih\n",
    "                    + h_t_minus_1[layer] @ weight_hh.T\n",
    "                    + bias_hh\n",
    "                )\n",
    "\n",
    "                if self.enable_q:\n",
    "                    h_layer = self.q_sym_noscale(h_layer.clone(), self.bits, self.bits-2)\n",
    "                # h_layer_quantized, scale = self.quantize(h_layer.clone(), self.bits)\n",
    "                # h_layer_q = self.dequantize(h_layer_quantized, scale)\n",
    "                #import pdb; pdb.set_trace()\n",
    "\n",
    "                h_t_new.append(h_layer)\n",
    "\n",
    "            h_t = torch.stack(h_t_new)\n",
    "            output.append(h_t[-1])\n",
    "\n",
    "            h_t_minus_1 = h_t.detach()\n",
    "\n",
    "        output = torch.stack(output)\n",
    "        if self.rnn.batch_first:\n",
    "            output = output.transpose(0, 1)\n",
    "\n",
    "        if self.enable_q:\n",
    "            fc_weight = self.q_pow2_w(self.fc.weight.data)\n",
    "            fc_bias = self.q_pow2_w(self.fc.bias.data)\n",
    "            out = torch.matmul(output[:, -1, :], fc_weight.T) + fc_bias\n",
    "        else:\n",
    "            out = self.fc(output[:, -1, :])\n",
    "\n",
    "        if self.enable_q:\n",
    "            out_quantized, scale = self.quantize(out.clone(), self.bits)\n",
    "            out = self.dequantize(out_quantized, scale)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained model\n",
    "model_pre = FSDNN_RNN(args['ysize'], args['rnn_hidden'], args['rnn_layers'], args['rnn_outputs'])\n",
    "model_pre.load_state_dict(torch.load('chkpt_t1.pt', weights_only=True)) #load pretrained \n",
    "\n",
    "# \n",
    "model = FSDNN_RNN_POW2WEIGHTS_Q(args['ysize'], args['rnn_hidden'], args['rnn_layers'], args['rnn_outputs'])\n",
    "pretrained_weights = model_pre.state_dict()\n",
    "new_model_dict = model.state_dict()\n",
    "pretrained_weights = {k: v for k, v in pretrained_weights.items() if k in new_model_dict}\n",
    "new_model_dict.update(pretrained_weights)\n",
    "model.load_state_dict(new_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.66666666666667\n",
      "91.66666666666667\n",
      "> \u001b[0;32m/tmp/ipykernel_1831/2859931736.py\u001b[0m(35)\u001b[0;36mq_pow2_w\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     33 \u001b[0;31m        \u001b[0mw_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     34 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 35 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0msgn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw_q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     36 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     37 \u001b[0;31m    \u001b[0;31m# quantized (modified pytorch doc implementation -> fixed layered input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# validate equivalence\n",
    "acc = validate_model(testset,testlabels,model_pre,**args)\n",
    "print(acc)\n",
    "acc = validate_model(testset,testlabels,model,**args)\n",
    "print(acc)\n",
    "model.enable_q = True\n",
    "acc = validate_model(testset,testlabels,model,**args)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 1000. Training loss: 3.26, Validation accuracy: 78.89%\n",
      "Epoch 2 of 1000. Training loss: 3.26, Validation accuracy: 78.89%\n",
      "Epoch 3 of 1000. Training loss: 3.26, Validation accuracy: 78.89%\n",
      "Epoch 4 of 1000. Training loss: 3.26, Validation accuracy: 78.89%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m acc_best \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#scheduler.step()\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     acc \u001b[38;5;241m=\u001b[39m validate_model(validset,validlabels,model,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/9_sandbox/fsdd_constrained/utils.py:82\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(trainset, trainlabels, model, optimizer, criterion, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m Y \u001b[38;5;241m=\u001b[39m trainlabels[b\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]:\u001b[38;5;28mmin\u001b[39m(trainlen,(b\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m])]\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#import pdb; pdb.set_trace()\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m#Propagate\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m posteriors \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m#Backpropagate\u001b[39;00m\n\u001b[1;32m     85\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(posteriors,Y)\n",
      "File \u001b[0;32m~/9_sandbox/fsdd_constrained/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/9_sandbox/fsdd_constrained/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 70\u001b[0m, in \u001b[0;36mFSDNN_RNN_POW2WEIGHTS_Q.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m     bias_hh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias_hh_l\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     68\u001b[0m xin \u001b[38;5;241m=\u001b[39m x[t] \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m h_t_new[layer\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 70\u001b[0m h_layer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight_ih\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_ih\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh_t_minus_1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight_hh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_hh\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_q:\n\u001b[1;32m     78\u001b[0m     h_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_sym_noscale(h_layer\u001b[38;5;241m.\u001b[39mclone(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbits, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbits\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# QAT\n",
    "## Training Setup\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=args['learning_rate'])\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "## Training Loop\n",
    "acc_best = 0\n",
    "for ep in range(1,args['epochs']+1):\n",
    "\n",
    "    # training\n",
    "    loss = train_model(trainset,trainlabels,model,optimizer,criterion,**args)\n",
    "    #scheduler.step()\n",
    "    acc = validate_model(validset,validlabels,model,**args)\n",
    "\n",
    "    # save best model\n",
    "    if acc > acc_best:\n",
    "        acc_best = acc\n",
    "        torch.save(model.state_dict(), 'chkpt_3.pt')    \n",
    "\n",
    "    # display progress\n",
    "    # if ep % 10 == 0:\n",
    "    #     print('Epoch {0:d} of {1:d}. Training loss: {2:.2f}, Validation accuracy: {3:.2f}%'.format(ep,args['epochs'],loss,acc))\n",
    "    print('Epoch {0:d} of {1:d}. Training loss: {2:.2f}, Validation accuracy: {3:.2f}%'.format(ep,args['epochs'],loss,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = validate_model(testset,testlabels,model,**args)\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
